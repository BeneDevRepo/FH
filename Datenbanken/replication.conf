#
# Replication configuration
#

database
{
	### PRIMARY SIDE SETTINGS

	# Plugin used to perform replication.
	# Leave it empty to use built-in replication.
	#
	# plugin =

	# Pattern (regular expression) that defines what tables must be included into
	# replication. By default, all tables are replicated.
	#
	# include_filter = 

	# Pattern (regular expression) that defines what tables must be excluded from
	# replication. By default, all tables are replicated.
	#
	# exclude_filter = 

	# Boolean parameters describing how replication errors must be handled.
	#
	# log_errors = true			# All errors (and warnings) are written to replication.log
	# report_errors = false		# Errors are returned to the client application
	# disable_on_error = true	# Replication is disabled after error

	### Parameters specific for built-in replication

	# Size of the local buffer used to accumulate changes that can be
	# deferred until the transaction commit/rollback. The bigger this value
	# the less disk access concurrency (related to journal IOPS) happens.
	#
	# For synchronous replication, it also affects number of network round-trips
	# between primary and replica hosts.
	# However, a larger buffer costs a longer replication "checkpoints"
	# (delay to synchronize the original database with its replica at commit).
	#
	# buffer_size = 1048576 # 1MB

	# Directory to store replication journal files.
	#
	# journal_directory = 

	# Prefix for replication journal file names. It will be automatically suffixed
	# with an ordinal sequential number. If not specified, database filename
	# (without path) is used as a prefix.
	#
	# journal_file_prefix =  

	# Maximum allowed size for a single replication segment.
	#
	# journal_segment_size = 16777216 # 16MB

	# Maximum allowed number of full replication segments. Once this limit is reached,
	# the replication process is temporarily delayed to allow the archiving to catch up. 
 	# If any of the full segments is not archived during one minute,
 	# the replication fails with an error.
 	#
	# Zero means an unlimited number of segments pending archiving.
	#
	# journal_segment_count = 8

	# Delay, in milliseconds, to wait before the changes are synchronously flushed
	# to the journal (usually at commit time). This allows multiple concurrently committing
	# transactions to amortise I/O costs by sharing a single flush operation.
	#
	# Zero means no delay, i.e. "group flushing" is disabled.
	#
	# journal_group_flush_delay = 0

	# Directory for the archived journal files.
	#
	# Directory to store archived replication segments.
	# It also defines the $(archpathname) substitution macro (see below).
	#
	# journal_archive_directory = 

	# Program (complete command line with arguments) that is executed when some
	# replication segment gets full and needs archiving.
	#
	# This program MUST return zero ONLY if archiving has been performed successfully.
	# In particular, it MUST return non-zero if the target archive already exists.
	#
	# Special predefined macros are available:
	#   $(filename) - file name (without path) of the journal segment being archived
	#   $(pathname) - full path name of the journal segment being archived
	#     same as journal_directory + $(filename)
	#   $(archivepathname) - suggested full path name for the archived segment
	#     same as journal_archive_directory + $(filename)
	#
	# Simplest configuration is to use standard OS commands for archiving, e.g.:
	#
	# Linux: "test ! -f $(archivepathname) && cp $(pathname) $(archivepathname)"
	# or
	# Windows: "copy $(pathname) $(archivepathname)"
	#
	# journal_archive_command = 

	# Timeout, in seconds, to wait until incomplete segment is scheduled for archiving.
	# It allows to minimize the replication gap if the database is modified rarely.
	#
	# Zero means no intermediate archiving, i.e. segments are archived only after
	# reaching their maximum size (defined by journal_segment_size).
 	#
	# journal_archive_timeout = 60

	# Connection string to the replica database (used for synchronous replication only).
	# Expected format:
	#
	# [<login>:<password>@]<database connection string>
	#
	# Examples:
	#
	# server2:replica
	# john:smith@server2:replica
	# server2:/my/replica/database.fdb
	# john:smith@server2:/my/replica/database.fdb
	#
	# Multiple entries are allowed (for different synchronous replicas).
	#
	# sync_replica = 


	### REPLICA SIDE SETTINGS

	# Directory to search for the journal files to be replicated.
	#
	# journal_source_directory = 

	# Filter to limit replication to the particular source database (based on its GUID).
	# Expected format: "{XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX}"
	# Note that double quotes are mandatory, as well as curly braces.
	#
	# source_guid = 

	# If enabled, replication.log contains the detailed log of operations performed
	# by the replication server. Otherwise (by default), only errors and warnings are logged.
	#
	# verbose_logging = false

	# Timeout (in seconds) to wait before scanning for the new replication segments.
	#
	# It's used to pause the replication server when all existing segments are already applied
	# to the replica database and there are no new segments in the specified directory.
	#
	# apply_idle_timeout = 10

	# Timeout (in seconds) to wait before retrying to apply the queued segments after error.
	#
	# It's used to pause the replication server after some critical error happened during replication.
	# In this case, the server disconnects from the replica database, sleeps for the specified timeout,
	# then reconnects back and tries to re-apply the latest segments from the point of failure.
	#
	# apply_error_timeout = 60
}

#
# Database-specific settings belong here, e.g.
#
# (for the primary side)
#
# database = /your/db.fdb
# {
#   (for synchronous replication)
#
#   sync_replica = sysdba:masterkey@otherhost:/your/replica.fdb
#
#   (for asynchronous replication)
#
#   journal_directory = /your/db/journal
#   journal_archive_directory = /your/db/archive
#   journal_archive_timeout = 10
# }
#
# (for the replica side)
#
# database = /your/db.fdb
# {
#   journal_source_directory = /your/db/source
# }
